{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93b0c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1️ Configuración de rutas, entorno y MLflow\n",
    "# ============================================================\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "# --- Definir raíz del proyecto ---\n",
    "root_dir = Path.cwd().parent  # notebooks/ -> proyecto raíz\n",
    "sys.path.append(str(root_dir))  # para que Python encuentre 'src'\n",
    "\n",
    "# --- Carpetas principales ---\n",
    "data_raw = root_dir / \"data\" / \"raw\"\n",
    "data_intermediate = root_dir / \"data\" / \"intermediate\"\n",
    "data_processed = root_dir / \"data\" / \"processed\"\n",
    "model_dir = root_dir / \"models\"\n",
    "model_summary_dir = root_dir / \"reports\" / \"models_summary\"\n",
    "executed_notebook_dir = root_dir / \"notebooks\" / \"_executed\"\n",
    "\n",
    "for folder in [data_intermediate, data_processed, model_dir, model_summary_dir, executed_notebook_dir]:\n",
    "    folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Configuración MLflow ---\n",
    "mlruns_path = root_dir / \"mlruns\"\n",
    "mlruns_path.mkdir(exist_ok=True)\n",
    "mlflow.set_tracking_uri(f\"file:///{mlruns_path.as_posix()}\")\n",
    "experiment_name = \"default\"\n",
    "if mlflow.get_experiment_by_name(experiment_name) is None:\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# ============================================================\n",
    "# 2️ Imports de librerías y módulos propios\n",
    "# ============================================================\n",
    "from src.data.load_data import load_arff\n",
    "from src.features.feature_engineering import combine_rare, create_ordinal_features, add_frequency_features\n",
    "from src.models.train_models import train_and_evaluate_model\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Modelos\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# ============================================================\n",
    "# 3️ Carga y limpieza de datos\n",
    "# ============================================================\n",
    "df = load_arff(data_raw / \"CEE_DATA.arff\")\n",
    "\n",
    "# Eliminar duplicados\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Agrupamiento de clases de Performance\n",
    "df['Performance_grouped'] = df['Performance'].replace({\n",
    "    'Average':'Average/Good',\n",
    "    'Good':'Average/Good',\n",
    "    'Vg':'Vg',\n",
    "    'Excellent':'Excellent'\n",
    "})\n",
    "\n",
    "# Variable objetivo numérica\n",
    "df['Performance_num'] = LabelEncoder().fit_transform(df['Performance_grouped'])\n",
    "\n",
    "# ============================================================\n",
    "# 4️ Feature engineering\n",
    "# ============================================================\n",
    "categorical_cols = [\n",
    "    'Gender','Caste','coaching','time','Class_ten_education',\n",
    "    'twelve_education','medium','Father_occupation','Mother_occupation'\n",
    "]\n",
    "\n",
    "# Combinar categorías raras\n",
    "for col in categorical_cols:\n",
    "    combine_rare(df, col)\n",
    "\n",
    "# Variables ordinales\n",
    "df = create_ordinal_features(\n",
    "    df,\n",
    "    [\"Class_ X_Percentage\",\"Class_XII_Percentage\"],\n",
    "    [\"Poor\",\"Average\",\"Good\",\"Vg\",\"Excellent\"]\n",
    ")\n",
    "\n",
    "# Features de frecuencia\n",
    "df = add_frequency_features(df, categorical_cols)\n",
    "\n",
    "# Guardar dataset intermedio\n",
    "df.to_pickle(data_intermediate / \"df.pkl\")\n",
    "\n",
    "# ============================================================\n",
    "# 5️ Split y balanceo\n",
    "# ============================================================\n",
    "feature_cols = [col for col in df.columns if col.endswith('_freq') or col.endswith('_target_mean')] + ['Academic_Score']\n",
    "X = df[feature_cols]\n",
    "y = df['Performance_num']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "with open(data_processed / \"Xy_train_resampled.pkl\", \"wb\") as f:\n",
    "    pickle.dump((X_train_res, y_train_res), f)\n",
    "with open(data_processed / \"Xy_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump((X_test, y_test), f)\n",
    "\n",
    "# ============================================================\n",
    "# 6️ Preprocesamiento con Pipeline de Scikit-Learn\n",
    "# ============================================================\n",
    "numeric_cols = [\"Academic_Score\",\"Class_ X_Percentage\",\"Class_XII_Percentage\"]\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 7️ Entrenamiento y seguimiento de modelos\n",
    "# ============================================================\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "    'XGBoost': XGBClassifier(objective='multi:softprob', eval_metric='mlogloss', random_state=42,\n",
    "                             tree_method='hist', use_label_encoder=False, n_jobs=-1),\n",
    "    'CatBoost': CatBoostClassifier(iterations=300, verbose=0, random_seed=42, class_weights=[1,2,2]),\n",
    "    'ExtraTrees': ExtraTreesClassifier(random_state=42, n_jobs=-1, class_weight='balanced')\n",
    "}\n",
    "\n",
    "results_summary = []\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n--- Entrenando {name} ---\")\n",
    "    pipe = Pipeline([('preprocessor', preprocessor), ('classifier', model)])\n",
    "    \n",
    "    with mlflow.start_run(run_name=name):\n",
    "        best_model, f1_score, best_params = train_and_evaluate_model(\n",
    "            pipe, X_train_res, y_train_res, X_test, y_test\n",
    "        )\n",
    "        \n",
    "        # Guardar modelo\n",
    "        save_path = model_dir / f\"{name}_best_model_{timestamp}.pkl\"\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            pickle.dump(best_model, f)\n",
    "        \n",
    "        # Logging en MLflow\n",
    "        mlflow.log_params(best_params)\n",
    "        mlflow.log_metric(\"F1_CV\", f1_score)\n",
    "        mlflow.sklearn.log_model(best_model, artifact_path=\"models\")\n",
    "        \n",
    "        # Log de datasets y resumen\n",
    "        mlflow.log_artifact(data_intermediate / \"df.pkl\")\n",
    "        mlflow.log_artifact(data_processed / \"Xy_train_resampled.pkl\")\n",
    "        mlflow.log_artifact(data_processed / \"Xy_test.pkl\")\n",
    "        \n",
    "        results_summary.append({\"Model\": name, \"F1_CV\": f1_score})\n",
    "\n",
    "# ============================================================\n",
    "# 8️ Guardar resumen de resultados\n",
    "# ============================================================\n",
    "summary_file = model_summary_dir / f\"results_summary_{timestamp}.csv\"\n",
    "pd.DataFrame(results_summary).to_csv(summary_file, index=False)\n",
    "mlflow.log_artifact(summary_file)\n",
    "\n",
    "print(\"\\n Pipeline completado correctamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1050ae-ae83-4fcc-beea-85d94391ca68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
