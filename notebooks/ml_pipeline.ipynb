{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93b0c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 0️ Configuración inicial y librerías\n",
    "# ============================================================\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Ajustar ruta raíz del proyecto para importar src\n",
    "root_path = Path(os.getcwd()).parent  # asumimos que notebooks/ está en la raíz\n",
    "sys.path.append(str(root_path))\n",
    "\n",
    "# Directorio donde se guardarán los modelos entrenados\n",
    "model_dir = Path(root_path) / \"models\"\n",
    "model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# ML y Scikit-Learn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Modelos\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# MLflow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Nuestro código\n",
    "from src.data.load_data import load_arff\n",
    "from src.features.feature_engineering import FeatureEngineering\n",
    "from src.models.train_models import PipelineML\n",
    "\n",
    "# ============================================================\n",
    "# 1️ Cargar datos\n",
    "# ============================================================\n",
    "base_path = Path.cwd().parent  # Ajustar según tu estructura\n",
    "data_path = base_path / \"data/raw/CEE_DATA.arff\"\n",
    "\n",
    "# Usando la clase ARFFLoader\n",
    "loader = ARFFLoader(data_path)\n",
    "df = loader.load()\n",
    "\n",
    "# ============================================================\n",
    "# 2️ Definir columnas categóricas y ordinales\n",
    "# ============================================================\n",
    "categorical_cols = ['Gender','Caste','coaching','time','Class_ten_education',\n",
    "                    'twelve_education','medium','Father_occupation','Mother_occupation']\n",
    "\n",
    "ordinal_cols = [\"Class_ X_Percentage\",\"Class_XII_Percentage\"]\n",
    "ord_map = [\"Poor\",\"Average\",\"Good\",\"Vg\",\"Excellent\"]\n",
    "\n",
    "# ============================================================\n",
    "# 3️ Preprocesamiento y creación de features con FeatureEngineering\n",
    "# ============================================================\n",
    "fe = FeatureEngineering(ordinal_map=ord_map)\n",
    "\n",
    "# Combinar categorías raras\n",
    "for col in categorical_cols:\n",
    "    df = fe.combine_rare(df, col, threshold=0.2)\n",
    "\n",
    "# Ordinal encoding y Academic_Score\n",
    "df = fe.create_ordinal_features(df, ordinal_cols)\n",
    "\n",
    "# Agrupar target\n",
    "df['Performance_grouped'] = df['Performance'].replace({\n",
    "    'Average':'Average/Good','Good':'Average/Good',\n",
    "    'Vg':'Vg','Excellent':'Excellent'\n",
    "})\n",
    "df['Performance_num'] = LabelEncoder().fit_transform(df['Performance_grouped'])\n",
    "\n",
    "# Features de frecuencia y mean encoding\n",
    "df = fe.add_frequency_features(df, categorical_cols, target_col='Performance_num')\n",
    "\n",
    "# ============================================================\n",
    "# 4️ Preparar datos para entrenamiento\n",
    "# ============================================================\n",
    "X = df.drop(columns=['Performance', 'Performance_grouped', 'Performance_num'])\n",
    "y = df['Performance_num']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 5️ Definir modelos y parámetros (sin class_weight, SMOTE aplicado)\n",
    "# ============================================================\n",
    "models = {\n",
    "    'RandomForest': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'classifier__n_estimators': [300, 350],\n",
    "            'classifier__max_depth': [5, 10],\n",
    "            'classifier__min_samples_leaf': [3, 5],\n",
    "            'classifier__min_samples_split': [10, 12, 15],\n",
    "            'classifier__max_features': ['sqrt', 'log2'],\n",
    "            'classifier__bootstrap': [True, False]\n",
    "        }\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBClassifier(objective='multi:softprob', eval_metric='mlogloss', random_state=42,\n",
    "                               tree_method='hist', n_jobs=-1),\n",
    "        'params': {\n",
    "            'classifier__n_estimators': [100, 150],\n",
    "            'classifier__max_depth': [3, 4],\n",
    "            'classifier__learning_rate': [0.05, 0.1],\n",
    "            'classifier__subsample': [0.7, 0.9],\n",
    "            'classifier__colsample_bytree': [0.7, 0.9],\n",
    "            'classifier__gamma': [0, 1],\n",
    "            'classifier__reg_alpha': [0, 0.1],\n",
    "            'classifier__reg_lambda': [1, 1.5],\n",
    "            'classifier__min_child_weight': [1, 3, 5]\n",
    "        }\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'model': CatBoostClassifier(iterations=300, verbose=0, random_seed=42),\n",
    "        'params': {\n",
    "            'classifier__depth': [4, 6],\n",
    "            'classifier__learning_rate': [0.05, 0.07],\n",
    "            'classifier__l2_leaf_reg': [1, 3, 5],\n",
    "            'classifier__border_count': [64]\n",
    "        }\n",
    "    },\n",
    "    'ExtraTrees': {\n",
    "        \"model\": ExtraTreesClassifier(random_state=42, n_jobs=-1),\n",
    "        \"params\": {\n",
    "           \"classifier__n_estimators\": [200, 400],\n",
    "           \"classifier__max_depth\": [5, 10, None],\n",
    "           \"classifier__min_samples_split\": [2, 5],\n",
    "           \"classifier__min_samples_leaf\": [1, 3],\n",
    "           \"classifier__max_features\": [\"sqrt\", \"log2\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# 6️ Instanciar PipelineML y entrenar todos los modelos\n",
    "# ============================================================\n",
    "pipeline_ml = PipelineML(model_dir=model_dir, cv=5)\n",
    "\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "for model_name, model_dict in models.items():\n",
    "    print(f\"Entrenando {model_name}...\")\n",
    "\n",
    "    # Pipeline con SMOTE + preprocesador + clasificador\n",
    "    pipe = ImbPipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('classifier', model_dict['model'])\n",
    "    ])\n",
    "\n",
    "    run_name = f\"{model_name}_{datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        pipeline_ml.train_and_evaluate_model(pipe, X_train, y_train, X_test, y_test, params=model_dict['params'])\n",
    "\n",
    "# ============================================================\n",
    "# 7️ Guardar resumen de resultados\n",
    "# ============================================================\n",
    "results_dir = base_path / \"results\"\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "summary_path = results_dir / f\"summary_{datetime.now().strftime('%Y%m%d_%H%M')}.csv\"\n",
    "\n",
    "summary = pd.DataFrame(pipeline_ml.results_summary)  # todos los modelos\n",
    "summary.to_csv(summary_path, index=False)\n",
    "\n",
    "print(f\"Resumen guardado en {summary_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1050ae-ae83-4fcc-beea-85d94391ca68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
