# API de PredicciÃ³n con MLflow y FastAPI - Team 51

DocumentaciÃ³n para ConstrucciÃ³n y Uso de la Imagen Docker

---

## ğŸ“‹ DescripciÃ³n General

Este proyecto contiene una API REST desarrollada con **FastAPI** que sirve un modelo de Machine Learning para predecir calificaciones de estudiantes basÃ¡ndose en su edad y horas de estudio. El modelo estÃ¡ empaquetado en formato **MLflow** y se despliega mediante **Docker**.

## ğŸ“ Estructura del Proyecto

```
docker/
â”œâ”€â”€ Dockerfile                  # DefiniciÃ³n de la imagen Docker
â”œâ”€â”€ docker-requirements.txt     # Dependencias de Python para la API y para el modelo
â”œâ”€â”€ README.md                   # Este archivo
â”œâ”€â”€ api/
â”‚   â””â”€â”€ Team51_ML_API.py       # CÃ³digo fuente de la API FastAPI (Hola Mundo)
â””â”€â”€ model/                      # Modelo MLflow (artefactos)(Hola Mundo)
    â”œâ”€â”€ MLmodel
    â”œâ”€â”€ conda.yaml
    â”œâ”€â”€ python_env.yaml
    â”œâ”€â”€ requirements.txt
    â””â”€â”€ registered_model_meta
```

## âš™ï¸ Requisitos Previos

- Docker instalado en su sistema (versiÃ³n 20.10 o superior)
- ConexiÃ³n a internet (para descargar dependencias e imÃ¡genes base de Dcoker)
- Puerto 8880 disponible en su mÃ¡quina host

---

## ğŸ”¨ OpciÃ³n 1: Construir la Imagen desde el Dockerfile

### Paso 1: Descarga el proyecto del repositorio remoto al local

```bash
git clone https://github.com/jjmoyap/test-MLops-CEE_DATA.git
```

### Paso 2: Construye la imagen Docker

```bash
docker build --no-cache -t ml-service-51 -f docker/Dockerfile .
```

**ParÃ¡metros:**
- `t` : Nombre de la imagen
- `f` : Indica que el Dockerfile estÃ¡ en el directorio __docker__

Nota:
- Debes estar posicionado en la raÃ­z del proyecto 

â±ï¸ **Tiempo estimado:** 2-5 minutos (dependiendo de tu conexiÃ³n a internet y tu computadora)

### Paso 3: Verificar que la imagen se creÃ³ correctamente

```bash
docker images | grep ml-service-51
```

DeberÃ­as ver algo como:
```
ml-service-51    latest    abc123def456    2 minutes ago    500MB
```

### Paso 4: Ejecutar el contenedor

```bashx
docker run \                                                   
  -p 8880:8880 \
  --name mi_contenedor \
  ml-service-51
```

**ParÃ¡metros:**
- `-p 8880:8880` : Mapea puerto 8880 del host al 8880 del contenedor
- `--name mi_contenedor` : Asigna nombre al contenedor
- `ml-service-51` : Imagen a utilizar

### Paso 5: Verificar que el contenedor estÃ¡ ejecutÃ¡ndose

```bash
docker ps
```

DeberÃ­as ver el contenedor en estado "Up"

---

## ğŸŒ OpciÃ³n 2: Usar la Imagen PÃºblica

### Paso 1: Descargar la imagen pÃºblica desde Docker Hub

```bash
docker pull c1544c/ml-service-51:latest
```

> **Nota:** La imagen pÃºblica estÃ¡ disponible en DockerHub `c1544c/ml-service-51-api`

### Paso 2: Ejecutar el contenedor desde la imagen pÃºblica

```bash
docker run \                                                   
  -p 8880:8880 \
  --name mi_contenedor \
  c1544c/ml-service-51:latest
```


## ğŸ§ª Probar la API

### OpciÃ³n A: Desde el navegador

#### 1. Navega a la siguiente URL
```
http://127.0.0.1:8880/
```
**Respuesta esperada:** 
![Respuesta](img/probar1.png)


#### 2. DocumentaciÃ³n interactiva
```
http://127.0.0.1:8880/docs
```
PodrÃ¡s probar todos los endpoints desde la interfaz **Swagger UI**
![Respuesta](img/probar2.png)


### OpciÃ³n B: Desde la terminal con curl

#### 1. Health Check
```bash
curl http://127.0.0.1:8880
```
**Respuesta esperada:**
```json
{"message":"API de predicciÃ³n de desempeÃ±o acadÃ©mico (CEE Project)","status":"running","model_version":"best_model_global_RandomForest_20251109_1602.pkl"}
```

#### 2. PredicciÃ³n 
```bash
curl -X 'POST' \          
  'http://127.0.0.1:8880/predict' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "data": {
    "Gender": "Male",
    "Caste": "OBC",
    "coaching": "Yes",
    "time": "1-2 Hours",
    "Class_ten_education": "CBSE",
    "twelve_education": "State Board",
    "medium": "English",
    "Father_occupation": "Private Service",
    "Mother_occupation": "Housewife",
    "Class_X_Percentage": "Good",
    "Class_XII_Percentage": "Vg"
  }
}'
```

**Respuesta esperada:**
```json
{"prediction":"0","probability":0.604190289821873,"model_version":"best_model_global_RandomForest_20251109_1602.pkl"}
```


### OpciÃ³n C: Desde Python

```python
url = "http://127.0.0.1:8880/predict"

headers = {
    "accept": "application/json",
    "Content-Type": "application/json"
}

payload = {
    "data": {
        "Gender": "Male",
        "Caste": "OBC",
        "coaching": "Yes",
        "time": "1-2 Hours",
        "Class_ten_education": "CBSE",
        "twelve_education": "State Board",
        "medium": "English",
        "Father_occupation": "Private Service",
        "Mother_occupation": "Housewife",
        "Class_X_Percentage": "Good",
        "Class_XII_Percentage": "Vg"
    }
}

response = requests.post(url, json=payload, headers=headers)

print("Status:", response.status_code)
print("Response JSON:")
print(response.json())

```

---

## ğŸ› ï¸ GestiÃ³n del Contenedor

### Detener el contenedor
```bash
docker stop mi_contenedor
```

### Iniciar el contenedor detenido
```bash
docker start mi_contenedor
```

### Reiniciar el contenedor
```bash
docker restart mi_contenedor
```

### Ver logs en tiempo real
```bash
docker logs -f mi_contenedor
```

### Ejecutar comandos dentro del contenedor
```bash
docker exec -it mi_contenedor /bin/bash
```

### Eliminar el contenedor
```bash
docker rm -f mi_contenedor
```

### Eliminar la imagen
```bash
docker rmi mi_contenedor
```

### Ver estadÃ­sticas de uso del contenedor
```bash
docker stats mi_contenedor
```

---

## ğŸ› SoluciÃ³n de Problemas

### Problema: El contenedor no inicia

**SoluciÃ³n 1:** Verificar logs
```bash
docker logs mi_contenedor
```

**SoluciÃ³n 2:** Verificar que el puerto 8880 no estÃ© en uso
```bash
# macOS/Linux
lsof -i :8880

# Windows
netstat -ano | findstr :8880
```

**SoluciÃ³n 3:** Verificar que los archivos del modelo existen
```bash
ls -la model/
```

### Problema: La API responde lento

**SoluciÃ³n:** Asignar mÃ¡s recursos al contenedor Docker
```bash
docker run -d \
  --name team51-api-container \
  --memory="2g" \
  --cpus="2.0" \
  -p 8880:8880 \
  --name mi_contenedor \
  team51-api:latest
```

### Problema: No puedo conectarme a la API desde fuera del host

**SoluciÃ³n:** Verificar que el puerto estÃ¡ mapeado correctamente
```bash
docker ps  # Verifica que aparezca 0.0.0.0:8880->8880/tcp
```

### Problema: Error al instalar dependencias durante la construcciÃ³n

**SoluciÃ³n 1:** Limpiar la cachÃ© de Docker
```bash
docker builder prune
```

**SoluciÃ³n 2:** Construir sin cachÃ©
```bash
docker build --no-cache -t team51-api:latest .
```

---

## ğŸ—ï¸ Arquitectura del Proyecto

### Flujo de ejecuciÃ³n:

1. Dockerfile copia el modelo y el cÃ³digo de la API al contenedor
2. Se instalan las dependencias de Python
3. Se crea un usuario no-root para seguridad
4. Uvicorn inicia el servidor FastAPI en el puerto 8880
5. MLflow carga el modelo desde `/ml/model`
6. La API queda lista para recibir peticiones

### Endpoints disponibles:

| MÃ©todo | Endpoint | DescripciÃ³n |
|--------|----------|-------------|
| `GET` | `/` | Mensaje de bienvenida |
| `GET` | `/docs` | DocumentaciÃ³n interactiva Swagger |
| `POST` | `/open` | PredicciÃ³n para un estudiante |
| `POST` | `/predict` | Modelo de predicciÃ³n |



## âœ¨ Mejores PrÃ¡cticas

### 1. Seguridad:
- âœ… La imagen ejecuta el servicio con usuario no-root (`team51`)
- âœ… No incluir credenciales en el Dockerfile
- âœ… Usar variables de entorno para configuraciÃ³n sensible

### 2. OptimizaciÃ³n:
- âœ… Usar imÃ¡genes base slim para reducir el tamaÃ±o
- âœ… Multi-stage builds si el proyecto crece
- âœ… Aprovechar la cachÃ© de Docker organizando comandos correctamente

### 3. Monitoreo:
- âœ… Implementar health checks
- âœ… Centralizar logs
- âœ… Usar herramientas de monitoreo (Prometheus, Grafana)

### 4. CI/CD:
- âœ… Automatizar construcciÃ³n de imÃ¡genes
- âœ… Versionar las imÃ¡genes (tags semÃ¡nticos)
- âœ… Ejecutar pruebas antes de publicar

---

## ğŸ“š Recursos Adicionales

### DocumentaciÃ³n oficial:
- [Docker](https://docs.docker.com/)
- [FastAPI](https://fastapi.tiangolo.com/)
- [MLflow](https://www.mlflow.org/docs/latest/index.html)
- [Uvicorn](https://www.uvicorn.org/)

### Tutoriales recomendados:
- [Docker para principiantes](https://docker-curriculum.com/)
- [FastAPI tutorial](https://fastapi.tiangolo.com/tutorial/)
- [MLflow tracking](https://www.mlflow.org/docs/latest/tracking.html)

---

## ğŸ‘¥ Contacto y Soporte

- **Equipo:** Team 51
- **Proyecto:** MLOps - Sistema de PredicciÃ³n de Calificaciones
- **Repositorio:** test-MLops-CEE_DATA
- **Imagen Docker Hub:** [c1544c/team51-api](https://hub.docker.com/r/c1544c/team51-api)

Para reportar problemas o sugerencias, por favor crear un issue en el repositorio.

---

## ğŸ“ Changelog

### VersiÃ³n 1.1.0 (15 de noviembre de 2025)

- âœ¨ ImplementaciÃ³n inicial de la API con FastAPI
- ğŸ³ DockerizaciÃ³n del servicio
- ğŸ“Š Endpoints de predicciÃ³n
- ğŸ“– DocumentaciÃ³n completa

---

## ğŸ“„ Licencia

Este proyecto es parte del curso de MLOps - Team 51

---

**Â¡Gracias por usar nuestra API! ğŸš€**
